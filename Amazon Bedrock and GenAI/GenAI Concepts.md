# Tokenization

# Context Window
- The number of tokens an LLM can consider when generating text.
- The larger then context window , the more information and coherence.
- Large context window require more memory and processing power.
- First factor to look at when considering a model.

# Embeddings
- 